{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toxic Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook attempts to classify bad comments on Wikipedia, for Kaggle challenge https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge. The technique is a non-tensorflow implementation called Naive Bayes SVM, the original implementation is from https://www.kaggle.com/jhoward/nb-svm-strong-linear-baseline. I use these functions and try out other models using the feature set to see if a higher AUC can be obtained.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First load the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer\n",
    "\n",
    "train_data = pd.DataFrame(pd.read_csv(\"./train.csv\"))\n",
    "test_data = pd.DataFrame(pd.read_csv(\"./test.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look at the structure of the training set and partition the training data into features and labels. Afterwards plot the distribution of the target labels to view the prevelance of certain types of labels. Toxic comments appear 9.5% of the time, insult and obscene material 5% of the time while some of the more controversial content makes up less than 1% of the data. There is evidently class imbalances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\r\\nWhy the edits made under my use...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\r\\nMore\\r\\nI can't make any real suggestions...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\r\\nWhy the edits made under my use...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\r\\nMore\\r\\nI can't make any real suggestions...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = train_data[[\"comment_text\"]]\n",
    "y = train_data[[\"toxic\",\"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.095844</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>0.052948</td>\n",
       "      <td>0.002996</td>\n",
       "      <td>0.049364</td>\n",
       "      <td>0.008805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.294379</td>\n",
       "      <td>0.099477</td>\n",
       "      <td>0.223931</td>\n",
       "      <td>0.054650</td>\n",
       "      <td>0.216627</td>\n",
       "      <td>0.093420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               toxic   severe_toxic        obscene         threat  \\\n",
       "count  159571.000000  159571.000000  159571.000000  159571.000000   \n",
       "mean        0.095844       0.009996       0.052948       0.002996   \n",
       "std         0.294379       0.099477       0.223931       0.054650   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "              insult  identity_hate  \n",
       "count  159571.000000  159571.000000  \n",
       "mean        0.049364       0.008805  \n",
       "std         0.216627       0.093420  \n",
       "min         0.000000       0.000000  \n",
       "25%         0.000000       0.000000  \n",
       "50%         0.000000       0.000000  \n",
       "75%         0.000000       0.000000  \n",
       "max         1.000000       1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "df_y_train = pd.DataFrame(y)\n",
    "df_y_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD9CAYAAABQvqc9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wPp3xBohSr6VgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2201cb04c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "proportions = [sum(df_y_train[col]) / len(df_y_train) for col in df_y_train.columns]\n",
    "plt.bar(df_y_train.columns, proportions)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to work with the text data we must remove any punctuation and markers from the text, so that they can be tokenized correctly. Onced cleaned we pass the text into the term frequency inverse document frequency transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re, string\n",
    "\n",
    "token = re.compile(f'([{string.punctuation}“”¨«»®´·º½¾¿¡§£₤‘’])')\n",
    "def tokenize(s):\n",
    "    return token.sub(r' \\1 ', s).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vect = TfidfVectorizer(min_df=3,\n",
    "                             max_df=0.9,\n",
    "                             lowercase=True, \n",
    "                             analyzer = 'word', \n",
    "                             stop_words='english', \n",
    "                             dtype=np.float32, \n",
    "                             tokenizer = tokenize, \n",
    "                             strip_accents='unicode',\n",
    "                             use_idf = 1,\n",
    "                             smooth_idf=1,\n",
    "                             sublinear_tf=1)\n",
    "tfidf_train_data = tfidf_vect.fit_transform(train_data.comment_text)\n",
    "tfidf_testing_data = tfidf_vect.transform(test_data.comment_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import VotingClassifier, RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the Naive baives feature function which is then used to transform the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prob(y_i, y):\n",
    "    p = tfidf_train_data[y==y_i].sum(0)\n",
    "    return (p+1) / ((y==y_i).sum() + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def create_model(y, model):\n",
    "    y = y.values\n",
    "    r = np.log(prob(1, y) / prob(0, y))\n",
    "    model = copy.deepcopy(model)\n",
    "    x_nb = tfidf_train_data.multiply(r)\n",
    "    return model.fit(x_nb, y), r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log_model(y):\n",
    "    y = y.values\n",
    "    r = np.log(prob(1, y) / prob(0, y))\n",
    "    model = LogisticRegression(C=4, dual=True)\n",
    "    x_nb = tfidf_train_data.multiply(r)\n",
    "    return model.fit(x_nb, y), r\n",
    "\n",
    "column_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "predictions_log = np.zeros((len(test_data), len(column_names)))\n",
    "for i, j in enumerate(column_names):\n",
    "    m, r = log_model(y[j])\n",
    "    predictions_log[:,i] = m.predict_proba(tfidf_testing_data.multiply(r))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "column_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "def svc_model(y):\n",
    "    y = y.values\n",
    "    r = np.log(prob(1, y) / prob(0, y))\n",
    "    model = LinearSVC()\n",
    "    model = CalibratedClassifierCV(model)\n",
    "    x_nb = tfidf_train_data.multiply(r)\n",
    "    return model.fit(x_nb, y), r\n",
    "\n",
    "predictions_svc = np.zeros((len(test_data), len(column_names)))\n",
    "for i, j in enumerate(column_names):\n",
    "    m, r = svc_model(y[j])\n",
    "    predictions_svc[:,i] = m.predict_proba(tfidf_testing_data.multiply(r))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "def forest_model(y):\n",
    "    y = y.values\n",
    "    r = np.log(prob(1, y) / prob(0, y))\n",
    "    model = RandomForestClassifier()\n",
    "    x_nb = tfidf_train_data.multiply(r)\n",
    "    return model.fit(x_nb, y), r\n",
    "\n",
    "predictions_forest = np.zeros((len(test_data), len(column_names)))\n",
    "for i, j in enumerate(column_names):\n",
    "    m, r = forest_model(y[j])\n",
    "    predictions_forest[:,i] = m.predict_proba(tfidf_testing_data.multiply(r))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_aggregate = np.zeros((len(test_data), len(column_names)))\n",
    "\n",
    "predictions_aggregate[:,i] = (predictions_log[:,i] + predictions_svc[:,i] + predictions_forest[:,i]) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "timestr = time.strftime(\"%Y-%m-%d %H%M\")\n",
    "\n",
    "subm = pd.read_csv('./sample_submission.csv')\n",
    "test_submission = pd.DataFrame({'id': subm[\"id\"]})\n",
    "submission = pd.concat([test_submission, pd.DataFrame(predictions_aggregate, columns = column_names)], axis=1)\n",
    "submission.to_csv('submission%s.csv' % timestr, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Logistic regression models for each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "column_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "predictions_logistic = np.zeros((len(testing_data), len(column_names)))\n",
    "\n",
    "param_grid = {\n",
    "             'C': [1, 5, 10, 20],\n",
    "             'class_weight': ['balanced']\n",
    "             }\n",
    "\n",
    "for i, col in enumerate(column_names):\n",
    "    gridsearch_log = GridSearchCV(LogisticRegression(), param_grid = param_grid, cv=3)\n",
    "    \n",
    "    gridsearch_log.fit(tfidf_train_data, y[col])\n",
    "    predictions_logistic[:,i] = gridsearch_log.predict(tfidf_testing_data)\n",
    "    \n",
    "predictions_logistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train SVM models for each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "column_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "predictions_svm = np.zeros((len(testing_data), len(column_names)))\n",
    "\n",
    "param_grid = {'gamma': [0.1, 1, 5, 10]\n",
    "             'C': [1, 5, 10, 20]\n",
    "             }\n",
    "\n",
    "for i, col in enumerate(column_names):\n",
    "    gridsearch_svm = GridSearchCV(SVC(), param_grid = param_grid, cv=3)\n",
    "    \n",
    "    gridsearch_svm.fit(tfidf_train_data, y[col])\n",
    "    predictions_svm[:,i] = gridsearch_svm.predict(tfidf_testing_data)\n",
    "    \n",
    "predictions_sv,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "y_val_df = pd.DataFrame(y_val, columns = column_names)\n",
    "predictions = [predictions_logistic]\n",
    "for prediction in predictions:\n",
    "    print('----------------')\n",
    "    for column in prediction.columns:\n",
    "        print(column, roc_auc_score(y_val_df[column], prediction[column]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "predictions_df = pd.DataFrame(np.c_[testing_data.id,predictions_logistic])\n",
    "predictions_df.columns = ['id', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "predictions_df.to_csv(\"test_predictions.csv\",index=False)\n",
    "predictions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
