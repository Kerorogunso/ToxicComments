{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Digit Classification\n",
    "\n",
    "Using standard out of box methods for machine learning one can achieve high levels of acccuracy for reading handwritten characters. Stochastic gradient descent and random forest classifiers are used while tuning the hyperparameters to achieve a very high level of accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "\n",
    "Scikit-learn has its own repository of standard datasets that can be used to practice its machine learning capabilities. In particular the MNIST is the most iconic dataset containing 70,000 instances of 28x28 handwritten digits and is the textbook dataset for any beginner machine learning practitioner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 784) (70000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_mldata\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "mnist = fetch_mldata('MNIST Original')\n",
    "X, y = mnist[\"data\"], mnist[\"target\"]\n",
    "print(X.shape,y.shape)\n",
    "\n",
    "# Hide warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is represented as a 784 dimension vector but is really a 28x28 pixel image. The intensity varies from 0 to 255 which is the grayscale value. We can recover this representation by reshaping the vector using numpy and matplotlibs imshow method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data = pd.DataFrame(pd.read_csv(\"./train.csv\"))\n",
    "test_data = pd.DataFrame(pd.read_csv(\"./test.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "2       0    ...            0         0         0         0         0   \n",
       "3       0    ...            0         0         0         0         0   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "3         0         0         0         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data.drop(['label'], axis=1)\n",
    "y_train = train_data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       0       0       0   \n",
       "3       0       0       0       0       0       0       0       0       0   \n",
       "4       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "2       0    ...            0         0         0         0         0   \n",
       "3       0    ...            0         0         0         0         0   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "3         0         0         0         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prior to training one must rescale the data otherwise nodes with "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255\n",
    "X_val = X_val / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to make use of the convolutions we must convert the training data into an array to preserve the spatial structure of the pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "\n",
    "X_train_array = np.array(X_train).reshape(len(X_train), 1, 28, 28)\n",
    "X_val_array = np.array(X_val).reshape(len(X_val), 1, 28, 28)\n",
    "y_train_cat = np_utils.to_categorical(y_train,10)\n",
    "y_val_cat = np_utils.to_categorical(y_val, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dropout, Activation, Dense, Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "def keras_model(activation = 'relu', dropout=0.2, nodes_per_layer = 32, loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy']):\n",
    "    my_model = Sequential()\n",
    "    my_model.add(Conv2D(filters=32, kernel_size = (2,2), padding='same', activation = 'relu', input_shape = (1, 28,28)))\n",
    "    my_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    my_model.add(Dropout(dropout))\n",
    "    my_model.add(Conv2D(filters=64, kernel_size = (2,2), padding='same', activation='relu'))\n",
    "    my_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    my_model.add(Dropout(dropout))\n",
    "    my_model.add(Conv2D(filters=128, kernel_size=(2,2), padding='same', activation='relu'))\n",
    "    my_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    my_model.add(Dropout(dropout))\n",
    "    my_model.add(Flatten())\n",
    "    my_model.add(Dense(nodes_per_layer, activation=activation))\n",
    "    my_model.add(Dense(10, activation=\"softmax\"))\n",
    "    \n",
    "    my_model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "    return my_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a simple 3 layer convolution with max pooling and a fully connected layer. Activations are all ReLU except for in the dense penultimate dense layer. Kernel size 2 to reduce the filter size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 28, 28)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 32, 14, 14)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32, 14, 14)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 14, 14)        8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 64, 7, 7)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64, 7, 7)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 128, 7, 7)         32896     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 128, 3, 3)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128, 3, 3)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                36896     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 78,538.0\n",
      "Trainable params: 78,538.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "my_model = keras_model()\n",
    "my_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "33600/33600 [==============================] - 14s - loss: 0.5512 - acc: 0.8197    \n",
      "Epoch 2/20\n",
      "33600/33600 [==============================] - 12s - loss: 0.1541 - acc: 0.9527    \n",
      "Epoch 3/20\n",
      "33600/33600 [==============================] - 12s - loss: 0.1057 - acc: 0.9650    \n",
      "Epoch 4/20\n",
      "33600/33600 [==============================] - 12s - loss: 0.0842 - acc: 0.9735    \n",
      "Epoch 5/20\n",
      "33600/33600 [==============================] - 12s - loss: 0.0674 - acc: 0.9785    \n",
      "Epoch 6/20\n",
      "33600/33600 [==============================] - 12s - loss: 0.0606 - acc: 0.9804    \n",
      "Epoch 7/20\n",
      "33600/33600 [==============================] - 12s - loss: 0.0515 - acc: 0.9835    \n",
      "Epoch 8/20\n",
      "33600/33600 [==============================] - 12s - loss: 0.0471 - acc: 0.9851    \n",
      "Epoch 9/20\n",
      "33600/33600 [==============================] - 12s - loss: 0.0437 - acc: 0.9857    \n",
      "Epoch 10/20\n",
      "33600/33600 [==============================] - 12s - loss: 0.0402 - acc: 0.9872    \n",
      "Epoch 11/20\n",
      "33600/33600 [==============================] - 12s - loss: 0.0368 - acc: 0.9874    \n",
      "Epoch 12/20\n",
      "33600/33600 [==============================] - 12s - loss: 0.0360 - acc: 0.9880    \n",
      "Epoch 13/20\n",
      "33600/33600 [==============================] - 12s - loss: 0.0328 - acc: 0.9892    \n",
      "Epoch 14/20\n",
      "33600/33600 [==============================] - 12s - loss: 0.0323 - acc: 0.9893    \n",
      "Epoch 15/20\n",
      "33600/33600 [==============================] - 12s - loss: 0.0316 - acc: 0.9896    \n",
      "Epoch 16/20\n",
      "33600/33600 [==============================] - 12s - loss: 0.0289 - acc: 0.9905    \n",
      "Epoch 17/20\n",
      "33600/33600 [==============================] - 12s - loss: 0.0275 - acc: 0.9904    \n",
      "Epoch 18/20\n",
      "33600/33600 [==============================] - 12s - loss: 0.0279 - acc: 0.9913    \n",
      "Epoch 19/20\n",
      "33600/33600 [==============================] - 12s - loss: 0.0246 - acc: 0.9921    \n",
      "Epoch 20/20\n",
      "33600/33600 [==============================] - 12s - loss: 0.0244 - acc: 0.9919    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8cb8a2c9b0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='model.weights.best.hdf5', verbose=1, save_best_only=True)\n",
    "my_model.fit(X_train_array, y_cat, batch_size=128, epochs=20, callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Keras wrapper we can create a sci-kit learn classifier and run hyperparameter tuning on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "keras_model_sk = KerasClassifier(build_fn=keras_model,epochs=50,batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'dropout': [0.2, 0.4, 0.6, 0.8],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(keras_model_sk, param_grid = param_grid, cv=3, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dropout': 0.8}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grid_search' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-ff10d2863288>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_cat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'grid_search' is not defined"
     ]
    }
   ],
   "source": [
    "predictions = grid_search.evaluate(X_train_array, y_train_cat)\n",
    "predictions[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating the model on the validation set, we obtain 99.1% accuracy with 20% dropout and a 32 node fully connected layer at the end, all activated with ReLU's and a softmax for the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8320/8400 [============================>.] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9910714285714286"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.evaluate(X_val_array, y_val_cat)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training with Data Augmentation\n",
    "Now let us try training a separate model with the additional images generated by shifting the pixels. Using the Keras image data generator flow we can create many more training instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVEAAAD8CAYAAADOg5fGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIIMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8cb50c1080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib import pyplot\n",
    "from keras import backend as K\n",
    "from keras.datasets import mnist\n",
    "K.set_image_dim_ordering('th')\n",
    "import numpy as np\n",
    "\n",
    "X_array = np.array(X_train)\n",
    "X_array = X_array.reshape(X_train.shape[0],1,28,28)\n",
    "X_array = X_array.astype('float32')\n",
    "\n",
    "shift = 0.2\n",
    "datagen = ImageDataGenerator(width_shift_range = shift, height_shift_range= shift)\n",
    "datagen.fit(X_array)\n",
    "# Get one of the batch images\n",
    "for X_batch, y_batch in datagen.flow(X_array, y_train, batch_size=9):\n",
    "    for i in range(0,9):\n",
    "        pyplot.subplot(330 + 1 + i)\n",
    "        pyplot.imshow(X_batch[i].reshape(28, 28), cmap = pyplot.get_cmap('gray'))\n",
    "    pyplot.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for X_batch, y_batch in datagen.flow(X_array, y_train, batch_size=len(X_train)):\n",
    "    X_train_shift = X_batch\n",
    "    y_train_shift = y_batch\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAC7CAYAAAB1qmWGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEAkaOgBE4v8A9eCZZtHOXh0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8d2364b198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, axarr = pyplot.subplots(ncols=2)\n",
    "axarr[0].imshow(X_train.values[1].reshape(28,28), cmap=pyplot.get_cmap('gray'))\n",
    "axarr[1].imshow(X_train_shift[1].reshape(28, 28), cmap=pyplot.get_cmap('gray'))\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate the generated images to the existing training data, likewise do so for the labels. Take the combined label set and perform one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_augmented = np.concatenate((X_train_array, X_train_shift), axis=0)\n",
    "y_train_augmented = np.concatenate((y_train, y_train_shift), axis=0)\n",
    "\n",
    "y_train_augmented_cat = np_utils.to_categorical(y_train_augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 32, 28, 28)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 32, 14, 14)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 32, 14, 14)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 64, 14, 14)        8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 64, 7, 7)          0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64, 7, 7)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 128, 7, 7)         32896     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 128, 3, 3)         0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 128, 3, 3)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                36896     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 78,538.0\n",
      "Trainable params: 78,538.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "shifted_model = keras_model()\n",
    "shifted_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "67200/67200 [==============================] - 23s - loss: 0.6973 - acc: 0.7735    \n",
      "Epoch 2/20\n",
      "67200/67200 [==============================] - 23s - loss: 0.2371 - acc: 0.9249    \n",
      "Epoch 3/20\n",
      "67200/67200 [==============================] - 23s - loss: 0.1557 - acc: 0.9515    \n",
      "Epoch 4/20\n",
      "67200/67200 [==============================] - 23s - loss: 0.1201 - acc: 0.9617    \n",
      "Epoch 5/20\n",
      "67200/67200 [==============================] - 23s - loss: 0.0970 - acc: 0.9698    \n",
      "Epoch 6/20\n",
      "67200/67200 [==============================] - 23s - loss: 0.0856 - acc: 0.9729    \n",
      "Epoch 7/20\n",
      "67200/67200 [==============================] - 23s - loss: 0.0754 - acc: 0.9762    \n",
      "Epoch 8/20\n",
      "67200/67200 [==============================] - 23s - loss: 0.0679 - acc: 0.9785    \n",
      "Epoch 9/20\n",
      "67200/67200 [==============================] - 23s - loss: 0.0633 - acc: 0.9801    \n",
      "Epoch 10/20\n",
      "67200/67200 [==============================] - 23s - loss: 0.0579 - acc: 0.9810    \n",
      "Epoch 11/20\n",
      "67200/67200 [==============================] - 23s - loss: 0.0553 - acc: 0.9819    \n",
      "Epoch 12/20\n",
      "67200/67200 [==============================] - 23s - loss: 0.0510 - acc: 0.9836    \n",
      "Epoch 13/20\n",
      "67200/67200 [==============================] - 23s - loss: 0.0482 - acc: 0.9843    \n",
      "Epoch 14/20\n",
      "67200/67200 [==============================] - 23s - loss: 0.0458 - acc: 0.9846    \n",
      "Epoch 15/20\n",
      "67200/67200 [==============================] - 23s - loss: 0.0424 - acc: 0.9860    \n",
      "Epoch 16/20\n",
      "67200/67200 [==============================] - 23s - loss: 0.0417 - acc: 0.9865    \n",
      "Epoch 17/20\n",
      "67200/67200 [==============================] - 23s - loss: 0.0399 - acc: 0.9871    \n",
      "Epoch 18/20\n",
      "67200/67200 [==============================] - 23s - loss: 0.0397 - acc: 0.9875    \n",
      "Epoch 19/20\n",
      "67200/67200 [==============================] - 23s - loss: 0.0378 - acc: 0.9876    \n",
      "Epoch 20/20\n",
      "67200/67200 [==============================] - 23s - loss: 0.0371 - acc: 0.9878    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8cb355f898>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_2 = ModelCheckpoint(filepath='shiftmodel.weights.best.hdf5', verbose=1, save_best_only=True)\n",
    "shifted_model.fit(X_train_augmented, y_train_augmented_cat, batch_size = 128, epochs=20, callbacks=[checkpoint_2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding the augmented dataset with 20% pixel shifts actually created a lower accuracy on training but worked out better than the raw dataset by about 0.09%. The performance gains are negligible but did not overfit due to the interdependency of the newly created images. Perhaps it would be better to run pixel shifts on larger resolution images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8160/8400 [============================>.] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.99190476190476196"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shifted_model.evaluate(X_val_array, y_val_cat)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33600, 784)\n",
      "(33600,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_shift.shape)\n",
    "print(y_train_shift.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import IncrementalPCA, PCA\n",
    "\n",
    "# n_batches = 100\n",
    "# inc_pca = IncrementalPCA(n_components=154)\n",
    "# for X_batch in np.array_split(X_train, n_batches):\n",
    "#     inc_pca.partial_fit(X_batch)\n",
    "    \n",
    "# pca = PCA(n_components=0.95)\n",
    "# X_reduced = inc_pca.transform(X_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
