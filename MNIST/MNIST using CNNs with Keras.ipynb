{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Digit Classification\n",
    "\n",
    "Using standard out of box methods for machine learning one can achieve high levels of acccuracy for reading handwritten characters. Stochastic gradient descent and random forest classifiers are used while tuning the hyperparameters to achieve a very high level of accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "\n",
    "Scikit-learn has its own repository of standard datasets that can be used to practice its machine learning capabilities. In particular the MNIST is the most iconic dataset containing 70,000 instances of 28x28 handwritten digits and is the textbook dataset for any beginner machine learning practitioner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 784) (70000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_mldata\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "mnist = fetch_mldata('MNIST Original')\n",
    "X, y = mnist[\"data\"], mnist[\"target\"]\n",
    "print(X.shape,y.shape)\n",
    "\n",
    "# Hide warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is represented as a 784 dimension vector but is really a 28x28 pixel image. The intensity varies from 0 to 255 which is the grayscale value. We can recover this representation by reshaping the vector using numpy and matplotlibs imshow method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data = pd.DataFrame(pd.read_csv(\"./train.csv\"))\n",
    "test_data = pd.DataFrame(pd.read_csv(\"./test.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "2       0    ...            0         0         0         0         0   \n",
       "3       0    ...            0         0         0         0         0   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "3         0         0         0         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = train_data.drop(['label'], axis=1)\n",
    "y_train = train_data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       0       0       0   \n",
       "3       0       0       0       0       0       0       0       0       0   \n",
       "4       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "2       0    ...            0         0         0         0         0   \n",
       "3       0    ...            0         0         0         0         0   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "3         0         0         0         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prior to training one must rescale the data otherwise nodes with "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train / 255\n",
    "X_val = X_val / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVEAAAD8CAYAAADOg5fGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1dfdb8fdfd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib import pyplot\n",
    "from keras import backend as K\n",
    "from keras.datasets import mnist\n",
    "K.set_image_dim_ordering('th')\n",
    "import numpy as np\n",
    "\n",
    "X_array = np.array(X_train)\n",
    "X_array = X_array.reshape(X_train.shape[0],1,28,28)\n",
    "X_array = X_array.astype('float32')\n",
    "\n",
    "shift = 0.2\n",
    "datagen = ImageDataGenerator(width_shift_range = shift, height_shift_range= shift)\n",
    "datagen.fit(X_array)\n",
    "# Get one of the batch images\n",
    "for X_batch, y_batch in datagen.flow(X_array, y_train, batch_size=9):\n",
    "    for i in range(0,9):\n",
    "        pyplot.subplot(330 + 1 + i)\n",
    "        pyplot.imshow(X_batch[i].reshape(28, 28), cmap = pyplot.get_cmap('gray'))\n",
    "    pyplot.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for X_batch, y_batch in datagen.flow(X_array, y_train, batch_size=len(X_train)):\n",
    "    X_train_shift = X_batch.reshape(len(X_train),784)\n",
    "    y_train_shift = y_batch\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33600, 784)\n",
      "(33600,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_shift.shape)\n",
    "print(y_train_shift.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAC7CAYAAAB1qmWGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEAQNHQCC+D8xFhWJu65LAwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1dfa65064a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, axarr = pyplot.subplots(ncols=2)\n",
    "axarr[0].imshow(X_train.values[1].reshape(28,28), cmap=pyplot.get_cmap('gray'))\n",
    "axarr[1].imshow(X_train_shift[1].reshape(28, 28), cmap=pyplot.get_cmap('gray'))\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to make use of the convolutions we must convert the training data into an array to preserve the spatial structure of the pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "\n",
    "X_train_array = np.array(X_train).reshape(len(X_train), 1, 28, 28)\n",
    "X_test_val_array = np.array(X_val).reshape(len(X_val), 1, 28, 28)\n",
    "y_cat = np_utils.to_categorical(y_train,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dropout, Activation, Dense, Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "def keras_model(activation = 'relu', dropout=0.2, nodes_per_layer = 32, loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy']):\n",
    "    my_model = Sequential()\n",
    "    my_model.add(Conv2D(filters=32, kernel_size = (2,2), padding='same', activation = 'relu', input_shape = (1, 28,28)))\n",
    "    my_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    my_model.add(Dropout(dropout))\n",
    "    my_model.add(Conv2D(filters=64, kernel_size = (2,2), padding='same', activation='relu'))\n",
    "    my_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    my_model.add(Dropout(dropout))\n",
    "    my_model.add(Conv2D(filters=128, kernel_size=(2,2), padding='same', activation='relu'))\n",
    "    my_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    my_model.add(Dropout(dropout))\n",
    "    my_model.add(Flatten())\n",
    "    my_model.add(Dense(nodes_per_layer, activation=activation))\n",
    "    my_model.add(Dense(10, activation=\"softmax\"))\n",
    "    \n",
    "    my_model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "    return my_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a simple 3 layer convolution with max pooling and a fully connected layer. Activations are all ReLU except for in the dense penultimate dense layer. Kernel size 2 to reduce the filter size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 28, 28)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 32, 14, 14)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32, 14, 14)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 14, 14)        8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 64, 7, 7)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64, 7, 7)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 128, 7, 7)         32896     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 128, 3, 3)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128, 3, 3)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                36896     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 78,538\n",
      "Trainable params: 78,538\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "my_model = keras_model()\n",
    "my_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "33600/33600 [==============================] - 205s 6ms/step - loss: 1.8164 - acc: 0.3919\n",
      "Epoch 2/20\n",
      "33600/33600 [==============================] - 204s 6ms/step - loss: 0.9989 - acc: 0.6751\n",
      "Epoch 3/20\n",
      "33600/33600 [==============================] - 193s 6ms/step - loss: 0.6413 - acc: 0.7964\n",
      "Epoch 4/20\n",
      "33600/33600 [==============================] - 212s 6ms/step - loss: 0.4720 - acc: 0.8518\n",
      "Epoch 5/20\n",
      "33600/33600 [==============================] - 208s 6ms/step - loss: 0.3735 - acc: 0.8822\n",
      "Epoch 6/20\n",
      "33600/33600 [==============================] - 200s 6ms/step - loss: 0.2954 - acc: 0.9099\n",
      "Epoch 7/20\n",
      "12288/33600 [=========>....................] - ETA: 2:14 - loss: 0.3042 - acc: 0.8993"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-af4ecdc912ac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mcheckpointer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'model.weights.best.hdf5'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmy_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_array\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_cat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2048\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcheckpointer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    963\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    964\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 965\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m    966\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    967\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1667\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1668\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1669\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1671\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1204\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1206\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1207\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1208\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2475\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2476\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2477\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    787\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 789\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    790\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    995\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 997\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    998\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1130\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1132\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1133\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1137\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1139\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1140\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1121\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='model.weights.best.hdf5', verbose=1, save_best_only=True)\n",
    "my_model.fit(X_train_array, y_cat, batch_size=128, epochs=20, callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Keras wrapper we can create a sci-kit learn classifier and run hyperparameter tuning on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "keras_model_sk = KerasClassifier(build_fn=keras_model,epochs=50,batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'dropout': [0.2, 0.4, 0.6, 0.8],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(keras_model_sk, param_grid = param_grid, cv=3, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dropout': 0.8}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33600/33600 [==============================] - 32s 940us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = grid_search.evaluate(X_train, y_cat)\n",
    "predictions[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shift the image by random pixels in various dimensions to create additional data to train on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the dataset by changing the brightness of certain sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib import pyplot\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28)\n",
    "X_train = X_train.astype('float32')\n",
    "\n",
    "datagen = ImageDataGenerator(zca_whitening=True)\n",
    "datagen.fit(X_train)\n",
    "\n",
    "for X_batch, y_batch in datagen.flow(X_train, y_train, batch_size=9):\n",
    "    # 3x3 images\n",
    "    for i in range(0, 9):\n",
    "        pyplot.subplot(330 + 1 + i)\n",
    "        pyplot.imshow(X_batch[i].reshape(28, 28), cmap=pyplot.get_cmap('gray'))\n",
    "    pyplot.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_augmented = pd.DataFrame(X_train)\n",
    "y_train_augmented = pd.DataFrame(y_train)\n",
    "\n",
    "for dx, dy in ((1,0), (0,1), (-1,0), (0,-1)):\n",
    "    for i in range(1, len(y_train)):\n",
    "        if i%1000 == 0: print(i)\n",
    "        X_train_augmented.append(shift_image(X_train[i:i+1].values,dx,dy))\n",
    "        y_train_augmented.append(y_train[i:i+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import IncrementalPCA, PCA\n",
    "\n",
    "n_batches = 100\n",
    "inc_pca = IncrementalPCA(n_components=154)\n",
    "for X_batch in np.array_split(X_train, n_batches):\n",
    "    inc_pca.partial_fit(X_batch)\n",
    "    \n",
    "pca = PCA(n_components=0.95)\n",
    "X_reduced = inc_pca.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, OneVsRestClassifier\n",
    "forest_clf = RandomForestClassifier()\n",
    "y_scores = cross_val_predict(forest_clf, X_reduced, y_train, cv=5)\n",
    "y_scores_no_reduce = cross_val_predict(forest_clf, X_train, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "n_estimators = 10\n",
    "bagging_clf = OneVsRestClassifier(BaggingClassifier(SVC(kernel='linear', probability=True), max_samples = 1.0/n_estimators, n_estimators = n_estimators))\n",
    "\n",
    "bagging_clf.fit(X_train, y_train)\n",
    "bagging_pred = bagging_clf.predict(X_train)\n",
    "accuracy_score(y_train, bagging_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_train, y_scores)\n",
    "accuracy2 = accuracy_score(y_train, y_scores_no_reduce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
